{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with strings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to extract quite a lot of interesting, structured information from text data simply by using string processing techiques. \n",
    "\n",
    "In this session, we'll see how to do some of these things, specifically calculating word frequencies and showing key-words-in-context (concordances). We'll do this for individual files and then you'll work together to write Python code which does this for a larger corpus of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading text files__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining a filepath using ```os.path.join()``` like we saw last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('..', 'data', 'Dickens_Expectations_1861.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to load the file that we want to work with.\n",
    "\n",
    "There are a number of ways to do this in Python, but the following should be considered \"best practice\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r', encoding='utf-8-sig') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we load the text file, we just have a simple string object which can be indexed and sliced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAT EXPECTATIONS\n",
      " 1867 Edition \n",
      "by Charles Dickens\n",
      "Chapter I\n",
      "My father's family name being Pirrip, \n"
     ]
    }
   ],
   "source": [
    "print(text[0:100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are some formatting things that are a little funky, such as lots of newline breaks.\n",
    "\n",
    "We can get rid of those by using the ```.replace()``` method on strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAT EXPECTATIONS  1867 Edition  by Charles Dickens Chapter I My father's family name being Pirrip, \n"
     ]
    }
   ],
   "source": [
    "text = text.replace('\\n', ' ')\n",
    "print(text[0:100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenize text__\n",
    "\n",
    "So far, we have one long string of characters. But we want to be able to work with individual words. To do that, we have to *tokenize* our data - in other words, to split it into individual tokens (or words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split(' ')\n",
    "words = [w for w in words if w != '']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get sentences with regex__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a similar logic to split the data into separate sentences.\n",
    "\n",
    "This time we use a bit of ```regex``` to do our string splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = re.split(r'[.?!]\\s*', text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find word frequencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count how many times an individual word appears manually, simply by iterating over the list of tokens and using a counter. \n",
    "\n",
    "To do this, we use a built in Python function called ```enumerate()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "# DIY <33\n",
    "counter = 0\n",
    "keyword = 'love'\n",
    "\n",
    "for word in words:\n",
    "    stripped = word.strip(string.punctuation)\n",
    "    if stripped.lower() == keyword:\n",
    "        counter += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Counter\n",
    "def clean_word(word):\n",
    "    return word.strip(string.punctuation).lower()\n",
    "\n",
    "cleaned = [clean_word(w) for w in words]\n",
    "\n",
    "counter = Counter(cleaned)\n",
    "counter['love']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a similar logic to find all sentences where a certain keyword appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "keyword_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    if re.search(pattern=f'[^A-Za-z0-9]{keyword}[^A-Za-z0-9]', string=sentence): # desperate try at regex that checks that the word is not part of another word (all characters before and after the word are not letters or numbers)\n",
    "        keyword_sentences.append(sentence)\n",
    "\n",
    "print(len(keyword_sentences))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python also has some built-in tools which we can use to count how many times a token appears in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some problems, though! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing keywords in context (KWIC, concordancing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dear fellow let me                             love                 him  and as to                                    \n",
      "another lady we are to                             love                 our neighbor sarah pocket returned                \n",
      "with anxiety of those i                            love                 if i could be less                                \n",
      "higher than your head my                           love                 said mr camilla i have                            \n",
      "expect to thank you my                             love                 without expecting any thanks or                   \n",
      "seen the object of one's                           love                 and duty for even so                              \n",
      "get myself to fall in                              love                 with you  you don't                               \n",
      "a certain man who made                             love                 to miss havisham i never                          \n",
      "haughty and too much in                            love                 to be advised by any                              \n",
      "me in a gush of                                    love                 and confidence at that time                       \n",
      "rigidity religion and her liver                    love                 these people hated me with                        \n",
      "to try it on for                                   love                 or money they dread him                           \n",
      "liberty excuse it for the                          love                 of poor old days no                               \n",
      "i loved estella with the                           love                 of a man i loved                                  \n",
      "she sat in the chair                               love                 her love her love her                             \n",
      "in the chair love her                              love                 her love her how does                             \n",
      "chair love her love her                            love                 her how does she use                              \n",
      "question at all she repeated                       love                 her love her love her                             \n",
      "all she repeated love her                          love                 her love her if she                               \n",
      "repeated love her love her                         love                 her if she favors you                             \n",
      "her if she favors you                              love                 her if she wounds you                             \n",
      "her if she wounds you                              love                 her if she tears your                             \n",
      "it will tear deeper                                love                 her love her love her                             \n",
      "tear deeper  love her                              love                 her love her never had                            \n",
      " love her love her                                 love                 her never had i seen                              \n",
      "that she might be loved                            love                 her she said the word                             \n",
      "had been hate instead of                           love                  despair  revenge                                 \n",
      "hurried passionate whisper what real               love                 is it is blind devotion                           \n",
      "the night miss havisham's words                    love                 her love her love her                             \n",
      "miss havisham's words love her                     love                 her love her sounded in                           \n",
      "words love her love her                            love                 her sounded in my ears                            \n",
      "said to my pillow i                                love                 her i love her i                                  \n",
      "pillow i love her i                                love                 her i love her hundreds                           \n",
      "her i love her i                                   love                 her hundreds of times then                        \n",
      "hand upon his knee i                               love                  i adore  estella                                 \n",
      "i should have replied that                         love                 was commonly reputed blind but                    \n",
      "you what would you have                            love                 replied the other you have                        \n",
      "did i never give her                               love                 cried miss havisham turning wildly                \n",
      "never give her a burning                           love                 inseparable from jealousy at all                  \n",
      "be weakness to return my                           love                 exclaimed miss havisham but yes                   \n",
      "but as there was no                                love                 lost between us that might                        \n",
      "generosity and disinterestedness in my             love                 for her that i could                              \n",
      "bright eyes somewheres wot you                     love                 the thoughts on o estella                         \n",
      "trembling voice you know i                         love                 you you know that i                               \n",
      "i may go still i                                   love                 you i have loved you                              \n",
      "comprehend when you say you                        love                 me i know what you                                \n",
      "replied quite true you cannot                      love                 him estella her fingers stopped                   \n",
      "to the few who truly                               love                 you among those few there                         \n",
      "my father and mother to                            love                 a girl who has no                                 \n",
      "a little affair of true                            love                 i felt as if the                                  \n",
      "for the genius of youthful                         love                 being in want of assistance                       \n",
      "little girl to rear and                            love                 and save from my fate                             \n",
      "you because i shall always                         love                 you but my need is                                \n",
      "had gone off sending his                           love                 to her over and over                              \n",
      "do what he would and                               love                 me though he did the                              \n",
      "and very beautiful and i                           love                 her with a last faint                             \n",
      "note to biddy with my                              love                 in it evidently biddy had                         \n",
      " but no you couldn't                               love                 him better than you do                            \n",
      "and are in charity and                             love                 with all mankind receive my                       \n",
      "you will have children to                          love                 and that some little fellow                       \n"
     ]
    }
   ],
   "source": [
    "# define keyword\n",
    "keyword = 'love'\n",
    "\n",
    "# for every token \n",
    "for idx, token in enumerate(cleaned):\n",
    "    # checks if token is the keyword\n",
    "    if token == keyword:\n",
    "        # get the 5 words before the keyword\n",
    "        before = ' '.join(cleaned[idx-5:idx])\n",
    "        # get the 5 words after the keyword\n",
    "        after = ' '.join(cleaned[idx+1:idx+6])\n",
    "\n",
    "        full = [before, token, after]\n",
    "        print('{:50} {:20} {:50}'.format(*full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In groups, work on the following exercises in class. \n",
    "\n",
    "I've left these somewhat underspecified, so you're welcome to solve them in whatever way you please, and to save the results in whatever format you think works best.\n",
    "\n",
    "- Write some code which searches through *all* of the novels in the folder called *100 English Novels* and shows how many times a given keyword appears in each novel.\n",
    "   - Save your results in a way which \n",
    "- Turn the KWIC in context code above into a function which can be used to show *all* occurrences of a keyword in the corpus. \n",
    "  - Bonus: Your results should show the same results as those above but with an additional column showing the filename\n",
    "  - Bonus: Write your function in such a way that a user can define the context window size to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_path = os.path.join('..', 'data', '100_novels', 'corpus')\n",
    "novel_files = os.listdir(novel_path)\n",
    "novel_files = [f for f in novel_files if f.endswith('.txt')] # solves the DS_Store problem\n",
    "\n",
    "novels = []\n",
    "\n",
    "for f in novel_files:\n",
    "    with open(os.path.join(novel_path, f), 'r') as novel:\n",
    "        novels.append(novel.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
